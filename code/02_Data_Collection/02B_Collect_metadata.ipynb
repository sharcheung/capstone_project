{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to gather metadata of TED talks, accessed using the urls that have been gathered in the previous notebook - *02A_Collect_urls*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, json, random, time\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load urls of talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "talks_urls = pd.read_csv('../../data/talks_urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do our brains process speech?</td>\n",
       "      <td>https://www.ted.com/talks/gareth_gaskell_how_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Give yourself permission to be creative</td>\n",
       "      <td>https://www.ted.com/talks/ethan_hawke_give_you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How caffeine and alcohol affect your sleep</td>\n",
       "      <td>https://www.ted.com/talks/matt_walker_how_caff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The myth of Jason, Medea, and the Golden Fleece</td>\n",
       "      <td>https://www.ted.com/talks/iseult_gillespie_the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A comprehensive, neighborhood-based response t...</td>\n",
       "      <td>https://www.ted.com/talks/kwame_owusu_kesse_a_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                  How do our brains process speech?   \n",
       "1            Give yourself permission to be creative   \n",
       "2         How caffeine and alcohol affect your sleep   \n",
       "3    The myth of Jason, Medea, and the Golden Fleece   \n",
       "4  A comprehensive, neighborhood-based response t...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.ted.com/talks/gareth_gaskell_how_d...  \n",
       "1  https://www.ted.com/talks/ethan_hawke_give_you...  \n",
       "2  https://www.ted.com/talks/matt_walker_how_caff...  \n",
       "3  https://www.ted.com/talks/iseult_gillespie_the...  \n",
       "4  https://www.ted.com/talks/kwame_owusu_kesse_a_...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe top 5 rows of talks_urls df\n",
    "talks_urls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of talks: \n",
      " 4104\n"
     ]
    }
   ],
   "source": [
    "print('Number of talks: \\n', talks_urls.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2B.1 Download data from urls using Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pd series to list; it's easier to work with a list\n",
    "urls = talks_urls['url'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to download talk's metadata and transcript from url\n",
    "def download_data(url):\n",
    "    \n",
    "    # instantiate empty dict to save downloaded data\n",
    "    downloaded_data = {}\n",
    "    \n",
    "    downloaded_data['url'] = url\n",
    "    \n",
    "    # talk url to make request from\n",
    "    url = url\n",
    "    \n",
    "    # make request for metadata\n",
    "    metadata_dl = requests.get(url, headers = {'User-agent': 'S bot 1.0'}).text\n",
    "    downloaded_data['metadata_dl'] = metadata_dl\n",
    "    \n",
    "    # to get transcript_url,\n",
    "    # modify talk url by inserting '/transcript/ before '?language=en'\n",
    "    transcript_url = url[:-12] + '/transcript' + url[-12:]\n",
    "    \n",
    "    # make request for transcript\n",
    "    transcript_dl = requests.get(transcript_url, headers = {'User-agent': 'S bot 1.0'}).text\n",
    "    downloaded_data['transcript_dl'] = transcript_dl\n",
    "    \n",
    "    return downloaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiprocessing to work in jupyter notebook\n",
    "# the function has to be defined in a .py file\n",
    "# import download_data.py\n",
    "import download_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: \n",
      " 9\n",
      "Batch 1 processed.\n",
      "Batch 2 processed.\n",
      "Batch 3 processed.\n",
      "Batch 4 processed.\n",
      "Batch 5 processed.\n",
      "Batch 6 processed.\n",
      "Batch 7 processed.\n",
      "Batch 8 processed.\n",
      "Batch 9 processed.\n",
      "Time taken:  844.5438024997711\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "t0 = time.time()\n",
    "\n",
    "# batch urls for staggering request\n",
    "urls_batched = [urls[i:i+500] for i in range(0, len(urls), 500)]\n",
    "print('Number of batches: \\n', len(urls_batched))\n",
    "\n",
    "# instantiate empty list to save downloaded data\n",
    "all_downloaded = []\n",
    "\n",
    "for n, batch in enumerate(urls_batched):\n",
    "    \n",
    "    # start 10 worker process\n",
    "    p = Pool(10)\n",
    "    # map download_data function to batch iterable\n",
    "    downloaded_data = p.map(download_data.download_data, batch)\n",
    "    p.terminate()\n",
    "    p.join()\n",
    "    \n",
    "    # append downloaded data to consolidated list \n",
    "    all_downloaded.extend(downloaded_data)\n",
    "    print(f'Batch {n+1} processed.')\n",
    "    \n",
    "    # sleep timer to stagger requests\n",
    "    sleep_duration = random.randint(2,10)\n",
    "    time.sleep(sleep_duration)\n",
    "    \n",
    "# print results of timer\n",
    "print('Time taken: ', (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>metadata_dl</th>\n",
       "      <th>transcript_dl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ted.com/talks/gareth_gaskell_how_d...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 8]&gt; &lt;html class...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 8]&gt; &lt;html class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ted.com/talks/ethan_hawke_give_you...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 8]&gt; &lt;html class...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 8]&gt; &lt;html class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ted.com/talks/matt_walker_how_caff...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 8]&gt; &lt;html class...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 8]&gt; &lt;html class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ted.com/talks/iseult_gillespie_the...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 8]&gt; &lt;html class...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 8]&gt; &lt;html class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ted.com/talks/kwame_owusu_kesse_a_...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 8]&gt; &lt;html class...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 8]&gt; &lt;html class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.ted.com/talks/gareth_gaskell_how_d...   \n",
       "1  https://www.ted.com/talks/ethan_hawke_give_you...   \n",
       "2  https://www.ted.com/talks/matt_walker_how_caff...   \n",
       "3  https://www.ted.com/talks/iseult_gillespie_the...   \n",
       "4  https://www.ted.com/talks/kwame_owusu_kesse_a_...   \n",
       "\n",
       "                                         metadata_dl  \\\n",
       "0  <!DOCTYPE html>\\n<!--[if lt IE 8]> <html class...   \n",
       "1  <!DOCTYPE html>\\n<!--[if lt IE 8]> <html class...   \n",
       "2  <!DOCTYPE html>\\n<!--[if lt IE 8]> <html class...   \n",
       "3  <!DOCTYPE html>\\n<!--[if lt IE 8]> <html class...   \n",
       "4  <!DOCTYPE html>\\n<!--[if lt IE 8]> <html class...   \n",
       "\n",
       "                                       transcript_dl  \n",
       "0  <!DOCTYPE html>\\n<!--[if lt IE 8]> <html class...  \n",
       "1  <!DOCTYPE html>\\n<!--[if lt IE 8]> <html class...  \n",
       "2  <!DOCTYPE html>\\n<!--[if lt IE 8]> <html class...  \n",
       "3  <!DOCTYPE html>\\n<!--[if lt IE 8]> <html class...  \n",
       "4  <!DOCTYPE html>\\n<!--[if lt IE 8]> <html class...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of talks downloaded:  4104\n"
     ]
    }
   ],
   "source": [
    "# convert list of successful downloads to a df\n",
    "raw_download = pd.DataFrame(all_downloaded)\n",
    "\n",
    "# observe top 5 rows of raw_download df\n",
    "display(raw_download.head())\n",
    "\n",
    "# number of talks\n",
    "print('Number of talks downloaded: ', raw_download.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as csv\n",
    "raw_download.to_csv('../../data/raw_download.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2B.2 Extract metadata and transcript from raw download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to optimise extraction tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create json object from downloaded metadata html\n",
    "def create_json(metadata_dl):\n",
    "    \n",
    "    # create BeautifulSoup obj and parse html\n",
    "    soup = BeautifulSoup(metadata_dl, 'lxml')\n",
    "    \n",
    "    # this element contains the talk's metadata\n",
    "    e_metadata = soup.find('script', {'data-spec': 'q'})\n",
    "    \n",
    "    if e_metadata is None:\n",
    "        count = 0\n",
    "        while count < 5:\n",
    "            e_metadata = soup.find('script', {'data-spec': 'q'})\n",
    "            count += 1\n",
    "            if e_metadata:\n",
    "                break\n",
    "                \n",
    "    if e_metadata is None:\n",
    "        metadata_json = ''\n",
    "    else:\n",
    "        metadata = e_metadata.text\n",
    "        # strip leading and trailing chars to obtain metadata in json format \n",
    "        strip_front = 'q(\"talkPage.init\",{\"el\":\"[data-talk-page]\",\"__INITIAL_DATA__\":'\n",
    "        strip_back = '})'\n",
    "        metadata = metadata[len(strip_front):-len(strip_back)]\n",
    "        # create json object from obtained metadata\n",
    "        metadata_json = json.loads(metadata)\n",
    "        \n",
    "    return metadata_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract values from each metadata category e.g. title, description, etc.\n",
    "def extract_value(list_of_keys, metadata_json):\n",
    "    for i in list_of_keys:\n",
    "        try:\n",
    "            metadata_json = metadata_json[i]\n",
    "            val = metadata_json\n",
    "        except:\n",
    "            val = ''\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract transcript from downloaded transcript html\n",
    "def extract_transcript(transcript_dl):\n",
    "    \n",
    "    # create BeautifulSoup obj and parse html\n",
    "    soup = BeautifulSoup(transcript_dl, 'lxml')\n",
    "\n",
    "    # this element contains the transcript text\n",
    "    words = soup.find_all('div', {'class': 'Grid__cell flx-s:1 p-r:4'})\n",
    "    \n",
    "    transcript = ''\n",
    "\n",
    "    for w in words:\n",
    "            transcript += w.text\n",
    "            transcript = ' '.join(transcript.split())\n",
    "\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract text from html object\n",
    "def html_to_text(html):\n",
    "    if str(html) != '':\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        return soup.text\n",
    "    else: \n",
    "        return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collect metadata and transcript\n",
    "def collect_metadata(metadata_dl, transcript_dl):\n",
    "\n",
    "    # instantiate empty dictionary to save metadata for each talk            \n",
    "    talk_metadata = {}\n",
    "\n",
    "    # get json object of metadata\n",
    "    metadata_json = create_json(metadata_dl)\n",
    "\n",
    "    if metadata_json != '':\n",
    "\n",
    "        # get metadata\n",
    "        # talk-related data:    \n",
    "        talk_metadata['id']               = extract_value(['talks', 0, 'id'], metadata_json)\n",
    "        talk_metadata['title']            = extract_value(['talks', 0, 'title'],metadata_json)\n",
    "        talk_metadata['description']      = extract_value(['talks', 0, 'description'], metadata_json)\n",
    "        talk_metadata['url']              = extract_value(['url'], metadata_json)\n",
    "        talk_metadata['num_views']        = extract_value(['talks', 0, 'viewed_count'], metadata_json)\n",
    "        talk_metadata['num_comments']     = extract_value(['comments', 'count'], metadata_json)\n",
    "\n",
    "        ## featured\n",
    "        talk_metadata['is_featured']      = extract_value(['talks', 0, 'is_featured'], metadata_json)\n",
    "\n",
    "        ## event\n",
    "        talk_metadata['video_type']       = extract_value(['talks', 0, 'video_type', 'name'], metadata_json)\n",
    "        talk_metadata['event']            = extract_value(['talks', 0, 'event'], metadata_json)\n",
    "        talk_metadata['institute_name']   = extract_value(['talks', 0, 'institute_partner_name'], metadata_json)\n",
    "        talk_metadata['salon_name']       = extract_value(['talks', 0, 'salon_partner_name'], metadata_json)  \n",
    "\n",
    "        ## tags\n",
    "        talk_metadata['tags']             = extract_value(['talks', 0, 'tags'], metadata_json)\n",
    "        talk_metadata['num_tags']         = len(extract_value(['talks', 0, 'tags'], metadata_json) or '')\n",
    "\n",
    "        ## more resources\n",
    "        talk_metadata['more_resources']   = extract_value(['talks', 0, 'more_resources'], metadata_json)\n",
    "        talk_metadata['num_resources']    = len(extract_value(['talks', 0, 'more_resources'], metadata_json) or '')\n",
    "\n",
    "        ## take action\n",
    "        talk_metadata['take_action']      = extract_value(['talks', 0, 'take_action'], metadata_json)\n",
    "        talk_metadata['num_actions']      = len(extract_value(['talks', 0, 'take_action'], metadata_json) or '')\n",
    "\n",
    "        ## recommendations\n",
    "        talk_metadata['recommendations']  = extract_value(['talks', 0, 'recommendations', \n",
    "                                            'rec_lists', 0, 'rec_items'], metadata_json)                                          \n",
    "        talk_metadata['num_recommend']    = len(extract_value(['talks', 0, 'recommendations', \n",
    "                                            'rec_lists', 0, 'rec_items'], metadata_json) or '')\n",
    "        ## citations\n",
    "        talk_metadata['has_citations']    = extract_value(['talks', 0, 'has_citations'], metadata_json)\n",
    "\n",
    "        ## languages\n",
    "        talk_metadata['languages']        = extract_value(['talks', 0, \n",
    "                                            'player_talks', 0, 'languages'], metadata_json)\n",
    "        talk_metadata['num_languages']    = len(extract_value(['talks', 0, \n",
    "                                            'player_talks', 0, 'languages'], metadata_json) or '')\n",
    "        talk_metadata['native_language']  = extract_value(['talks', 0, \n",
    "                                            'player_talks', 0, 'nativeLanguage'], metadata_json)\n",
    "\n",
    "        ## duration (in seconds), time and date\n",
    "        talk_metadata['duration']         = extract_value(['talks', 0, 'duration'], metadata_json)\n",
    "        talk_metadata['intro_duration']   = extract_value(['talks', 0, \n",
    "                                            'player_talks', 0, 'introDuration'], metadata_json)\n",
    "        talk_metadata['published_time']   = extract_value(['talks', 0, \n",
    "                                            'player_talks', 0, 'published'], metadata_json)\n",
    "        talk_metadata['recorded_date']    = extract_value(['talks', 0, 'recorded_at'], metadata_json)\n",
    "        \n",
    "        ## related talks\n",
    "        related_talks = extract_value(['talks', 0, 'related_talks'], metadata_json)\n",
    "\n",
    "        for i in range(len(related_talks)):\n",
    "            talk_metadata['related_talk_' + str(i+1)] = related_talks[i]['id']\n",
    "\n",
    "        # speaker-related data:    \n",
    "        talk_metadata['main_speaker'] = extract_value(['talks', 0, 'speaker_name'], metadata_json)\n",
    "\n",
    "        speakers = extract_value(['speakers'], metadata_json)\n",
    "        talk_metadata['num_speakers'] = len(speakers or '')\n",
    "\n",
    "        for i in range(len(speakers)):\n",
    "            talk_metadata['speaker_id_' + str(i+1)]              = speakers[i]['id']\n",
    "            talk_metadata['speaker_name_' + str(i+1)]            = (speakers[i]['firstname'] + ', '\n",
    "                                                                    + speakers[i]['lastname'] + ' '\n",
    "                                                                    + speakers[i]['middleinitial'])\n",
    "            talk_metadata['speaker_description_' + str(i+1)]     = speakers[i]['description']\n",
    "            talk_metadata['speaker_is_published_' + str(i+1)]    = speakers[i]['is_published']       \n",
    "            talk_metadata['speaker_what_others_say_' + str(i+1)] = speakers[i]['whatotherssay']\n",
    "            talk_metadata['speaker_who_they_are_' + str(i+1)]    = speakers[i]['whotheyare']\n",
    "            talk_metadata['speaker_why_listen_' + str(i+1)]      = html_to_text(speakers[i]['whylisten'])\n",
    "\n",
    "        # get transcript\n",
    "        talk_metadata['transcript'] = extract_transcript(transcript_dl)\n",
    "        \n",
    "    return talk_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract metadata and transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate empty list to save list of talks' metadata\n",
    "talks_metadata = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress count: 500\n",
      "Progress count: 1000\n",
      "Progress count: 1500\n",
      "Progress count: 2000\n",
      "Progress count: 2500\n",
      "Progress count: 3000\n",
      "Progress count: 3500\n",
      "Progress count: 4000\n",
      "Time taken:  184.83440399169922\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "t0 = time.time()\n",
    "\n",
    "for n, row in enumerate(raw_download.values):\n",
    "    # row index 1 and 2 correspond to talk's metadata and transcipt respectively\n",
    "    talk_metadata = collect_metadata(row[1], row[2])\n",
    "    \n",
    "    if talk_metadata == {}:\n",
    "        continue\n",
    "\n",
    "    # append downloaded talk metadata to consolidated list \n",
    "    talks_metadata.append(talk_metadata)\n",
    "    \n",
    "    # monitor progress of data extraction\n",
    "    if n > 0 and n % 500 == 0:\n",
    "        print(f'Progress count: {n}')        \n",
    "\n",
    "# print results of timer\n",
    "print('Time taken: ', (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successful extractions: \n",
      " 4045\n"
     ]
    }
   ],
   "source": [
    "# successful extractions\n",
    "print('Number of successful extractions: \\n', len(talks_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of metadata to a df\n",
    "ted_talks = pd.DataFrame(talks_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export metadata as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_talks.to_csv('../../data/ted_talks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
